{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F  \n",
    "import torch.optim as optim\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 242, 3)\n"
     ]
    }
   ],
   "source": [
    "input_image = cv2.imread('C:/Users/91932/OneDrive/Desktop/ML/VSCode30/DL/Pictures/dog.png')\n",
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D_scratch(nn.Module):\n",
    "    def __init__(self, n_kernels, kernel_size, input_channels, padding = 0, stride = 1):\n",
    "        super(Conv2D_scratch, self).__init__()\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size \n",
    "        self.input_channels = input_channels \n",
    "        self.padding = padding \n",
    "        self.stride = stride \n",
    "        # Initializing kernels with random weights\n",
    "        # (n_kernels , input_channels, kernel_height, kernel_width)\n",
    "        self.kernels = np.random.randn(n_kernels, input_channels, kernel_size, kernel_size) * 0.1\n",
    "        self.biases = np.zeros(n_kernels)           # (1 bias/kernel)/feature_map\n",
    "    \n",
    "    def forward(self, input):\n",
    "        if input.ndim == 3:               # (channels, height, width)\n",
    "            input = np.expand_dims(input, axis = 0)        # (1(batch dim), channels, height, width)\n",
    "        \n",
    "        n_batch, n_channels, n_height, n_width = input.shape      # image aspects \n",
    "        k_height, k_width = self.kernel_size, self.kernel_size    # kernel aspects \n",
    "        if self.padding > 0:\n",
    "            input_padded = np.pad(input, (0, 0), (0, 0), \n",
    "            (self.padding, self.padding), (self.padding, self.padding), mode = 'constant', constant_values = 0)\n",
    "            n_height_padded, n_width_padded = input_padded.shape[2], input_padded.shape[3]\n",
    "        else:\n",
    "            input_padded = input \n",
    "            n_height_padded, n_width_padded = n_height, n_width\n",
    "        \n",
    "        out_height = int((n_height_padded - k_height) / self.stride) + 1 \n",
    "        out_width = int((n_width_padded - k_width) / self.stride) + 1\n",
    "        # Initialize output feature maps: (batch_size, num_kernels, out_h, out_w)\n",
    "        output = np.zeros((n_batch, self.n_kernels, out_height, out_width)) \n",
    "        \n",
    "        for b in range(n_batch):\n",
    "            for k in range(self.n_kernels):\n",
    "                curr_kernel = self.kernels[k]\n",
    "                for y in range(out_height):\n",
    "                    for x in range(out_width):\n",
    "                        y_start = y*self.stride\n",
    "                        y_end = y_start + k_height\n",
    "                        x_start = x*self.stride \n",
    "                        x_end = x_start + k_width  \n",
    "                        \n",
    "                        # [batch_1, all channels, cur_height_region, cur_width_region]\n",
    "                        roi = input_padded[b, :, y_start:y_end, x_start:x_end]\n",
    "                        output[b, k, y, x] = np.sum(roi * curr_kernel) + self.biases[k]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling2D_scratch(nn.Module):\n",
    "    def __init__(self, pool_size = 2, stride = 2):\n",
    "        super(MaxPooling2D_scratch, self).__init__()\n",
    "        self.pool_size = pool_size \n",
    "        self.stride = stride \n",
    "    \n",
    "    def forward(self, input):\n",
    "        n_batch, n_channels, n_height, n_width = input.shape\n",
    "        p_height, p_width = self.pool_size, self.pool_size \n",
    "        \n",
    "        out_h = int((n_height - p_height) / self.stride) + 1 \n",
    "        out_w = int((n_width - p_width) / self.stride) + 1 \n",
    "        output = np.zeros((n_batch, n_channels, out_h, out_w))\n",
    "        \n",
    "        for b in range(n_batch):\n",
    "            for c in range(n_channels):\n",
    "                for y in range(out_h):\n",
    "                    for x in range(out_w):\n",
    "                        y_start = y*self.stride\n",
    "                        y_end = y_start + p_height\n",
    "                        x_start = x*self.stride\n",
    "                        x_end = x_start + p_width\n",
    "                        \n",
    "                        roi = input[b, c, y_start:y_end, x_start:x_end]\n",
    "                        output[b, c, y, x] = np.max(roi)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten_scratch:\n",
    "    def forward(self, input):\n",
    "        self.original_shape = input.shape    # (b, n_c, n_h, n_w)\n",
    "        return input.reshape(input.shape[0], -1)     # flattened shape : (b * n_c * n_h * n_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_scratch:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Dense_scratch, self).__init__()   \n",
    "        self.weights = np.random.randn(input_size, output_size) * 0.1 \n",
    "        self.biases = np.zeros((1, output_size))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input \n",
    "        return np.dot(input, self.weights) + self.biases\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu_scratch:\n",
    "    def forward(self, input):\n",
    "        self.input = input \n",
    "        return np.maximum(0, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling methods from all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 242, 3)\n"
     ]
    }
   ],
   "source": [
    "input_image = cv2.imread('C:/Users/91932/OneDrive/Desktop/ML/VSCode30/DL/Pictures/dog.png')\n",
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 252, 242])\n",
      "3\n",
      "252\n",
      "242\n"
     ]
    }
   ],
   "source": [
    "input_image_tensor = torch.from_numpy(input_image).permute(2, 0, 1)\n",
    "print(input_image_tensor.shape)\n",
    "print(input_image_tensor.shape[0])\n",
    "print(input_image_tensor.shape[1])\n",
    "print(input_image_tensor.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image after conv1 : (1, 4, 250, 240)\n",
      "Image after Relu_1 : (1, 4, 250, 240)\n"
     ]
    }
   ],
   "source": [
    "# Layer 1: Convolution + ReLU \n",
    "conv1 = Conv2D_scratch(\n",
    "    n_kernels = 4, \n",
    "    kernel_size = 3, \n",
    "    input_channels = input_image_tensor.shape[0],\n",
    "    stride = 1, \n",
    "    padding = 0\n",
    ")\n",
    "\n",
    "conv_output1 = conv1.forward(input_image_tensor)\n",
    "print(f'Image after conv1 : {conv_output1.shape}')\n",
    "\n",
    "reLu = Relu_scratch()\n",
    "relu_output1 = reLu.forward(conv_output1)\n",
    "print(f'Image after Relu_1 : {relu_output1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image after MaxPool_1 : (1, 4, 125, 120)\n"
     ]
    }
   ],
   "source": [
    "# Layer 2: Max Pooling \n",
    "MaxPool_2d = MaxPooling2D_scratch(pool_size = 2, stride = 2)\n",
    "pool_output1 = MaxPool_2d(relu_output1)\n",
    "print(f'Image after MaxPool_1 : {pool_output1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image after conv2 : (1, 8, 123, 118)\n",
      "Image after Relu_2 : (1, 8, 123, 118)\n"
     ]
    }
   ],
   "source": [
    "# Layer 3 : Convolution + ReLu\n",
    "conv2 = Conv2D_scratch(\n",
    "    n_kernels = 8, \n",
    "    kernel_size = 3,  \n",
    "    input_channels = conv_output1.shape[1],             # 4 input channels \n",
    "    stride = 1, \n",
    "    padding = 0\n",
    ")\n",
    "\n",
    "conv_output2 = conv2(pool_output1)\n",
    "print(f'Image after conv2 : {conv_output2.shape}')\n",
    "\n",
    "relu2 = Relu_scratch()  \n",
    "relu_output2 = relu2.forward(conv_output2)\n",
    "print(f'Image after Relu_2 : {relu_output2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Flatten shape: (1, 116112)\n"
     ]
    }
   ],
   "source": [
    "# Layer 4 : Flatten\n",
    "flat1 = Flatten_scratch()\n",
    "flatten_output = flat1.forward(relu_output2)\n",
    "print(f\"After Flatten shape: {flatten_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After FC1 (Output Layer) shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Layer 5 : Fully connected \n",
    "fc_input_size = flatten_output.shape[1]   \n",
    "num_classes = 2 # if a binary classification problem \n",
    "\n",
    "fc1 = Dense_scratch(input_size = fc_input_size, output_size = num_classes)\n",
    "fc_output1 = fc1.forward(flatten_output)\n",
    "\n",
    "print(f\"After FC1 (Output Layer) shape: {fc_output1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output (logits) from FC layer for batch 0: [-578.32088934  746.63684904]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw output (logits) from FC layer for batch 0: {fc_output1[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(fc_output1[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
